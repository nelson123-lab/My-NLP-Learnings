# NLP
-Process in which a we make a computer language understand, spare and extract human understandable languages. There are different areas of NLP.

## NER ( Named Entity Recognition )
- Part of Speech Tagging (POS)
- Syntactic Parsing
- Text Categorization
- Coreference Resolution
- Machine Translation

## NLU ( Natural Language Understanding )
- Relation Extraction
- Paraphrasing
- Semantic Parsing
- Sentiment Analysis
- Question and Answering
- Summarization


A POC (proof of concept) is an advanced demo project that reflects a real-world scenario. Since developing products from emerging technologies can be too risky or troublesome, POCs are often used to “prove” that a new technology, service, or idea is viable for the market.

A vision-language model typically consists of 3 key elements: an image encoder, a text encoder, and a strategy to fuse information from the two encoders. These key elements are tightly coupled together as the loss functions are designed around both the model architecture and the learning strategy.

## Latest LLM models
1. Llama (Large Language Model Meta AI)
LLaMA's ability to generate natural language text means that it can be used for various applications, from chatbots and virtual assistants to content creation and data analysis. In addition to its massive size and training data, LLaMA also uses various optimization techniques to improve its performance.

2. OPT (Open Pre-trained Transformer)
OPT is a series of open-sourced large causal language models which perform similar in performance to GPT3. The abstract from the paper is the following: Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning.

3. Alpaca
Alpaca is a small but capable 7B language model developed by researchers at Stanford University's Centre for Research on Foundation Models. It was fine-tuned from Meta AI's LLaMA 7B model and trained on 52K instruction-following demonstrations generated in the style of self-instruct using Open AI's text-davinci-003.

4. Dolly
Databricks' Dolly is an instruction-following large language model trained on the Databricks machine learning platform that is licensed for commercial use.
Dolly was trained on a much smaller language model of only six billion parameters versus 175 billion for GPT-3 (ChatGPT is fine-tuned on GPT-3.5).


